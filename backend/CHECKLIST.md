# å¾®å°æŒ‡æ•´åˆæª¢æŸ¥æ¸…å–® âœ…

## ğŸ“¦ æª”æ¡ˆæ¸…å–®

è§£å£“ç¸® `mxf_integration.zip` å¾Œæ‡‰è©²æœ‰é€™äº›æª”æ¡ˆï¼š

```
mxf_integration/
â”œâ”€â”€ README_INTEGRATION.md          # ğŸ“– å®Œæ•´æ•´åˆæŒ‡å—
â”œâ”€â”€ scraper_taifex_new.py          # ğŸ†• æ–°ç‰ˆçˆ¬èŸ²ï¼ˆæ”¯æ´ MXFï¼‰
â”œâ”€â”€ data_collector_v2.py           # ğŸ”„ ä¸»æ”¶é›†å™¨ï¼ˆé›™è³‡æ–™æºï¼‰
â”œâ”€â”€ run_daily_v2.py               # â° å®šæ™‚è…³æœ¬
â”œâ”€â”€ retail_ratio_collector_v2.py  # ğŸ“Š æ­·å²æ”¶é›†å™¨
â”œâ”€â”€ upgrade_database.py           # ğŸ”§ è³‡æ–™åº«å‡ç´šï¼ˆåŸ·è¡Œä¸€æ¬¡ï¼‰
â”œâ”€â”€ collect_mxf_history.py        # ğŸ“… æ‰¹é‡æ­·å²æ”¶é›†
â””â”€â”€ verify_scraper.py             # âœ… é©—è­‰å·¥å…·
```

---

## ğŸ¯ æ•´åˆæ­¥é©Ÿé€ŸæŸ¥

### 1ï¸âƒ£ å‚™ä»½ (5 åˆ†é˜)
```bash
cd ~/MyStock/backend
cp data/market_data.db data/market_data.db.backup_$(date +%Y%m%d)
```

### 2ï¸âƒ£ è¤‡è£½æª”æ¡ˆ (5 åˆ†é˜)
```bash
# è§£å£“ç¸®åˆ° backend ç›®éŒ„
unzip mxf_integration.zip -d ~/MyStock/backend/

# é‡å‘½åæª”æ¡ˆï¼ˆè¦†è“‹èˆŠç‰ˆï¼‰
cd ~/MyStock/backend
mv scraper_taifex_new.py scraper_taifex_v2.py
mv data_collector_v2.py data_collector.py.v2
mv run_daily_v2.py run_daily.py.v2
mv retail_ratio_collector_v2.py retail_ratio_collector.py.v2

# å‚™ä»½èˆŠæª”æ¡ˆ
mv scraper_taifex.py scraper_taifex.py.old
mv data_collector.py data_collector.py.old

# ä½¿ç”¨æ–°ç‰ˆ
mv scraper_taifex_v2.py scraper_taifex.py
mv data_collector.py.v2 data_collector.py
```

### 3ï¸âƒ£ å‡ç´šè³‡æ–™åº« (2 åˆ†é˜)
```bash
python upgrade_database.py
```

é æœŸè¼¸å‡ºï¼š
```
âœ“ å·²å‚™ä»½è‡³: data/market_data.db.backup_20260213_xxxxx
âœ“ mxf_futures_data è¡¨å‰µå»ºæˆåŠŸ
âœ“ Schema å‡ç´šå®Œæˆ
```

### 4ï¸âƒ£ æ¸¬è©¦æ”¶é›† (5 åˆ†é˜)
```bash
python data_collector.py
```

æª¢æŸ¥è¼¸å‡ºæ˜¯å¦æœ‰ï¼š
```
[4/6] æŠ“å– MXF å¾®å°æŒ‡ (æ•£æˆ¶æŒ‡æ¨™)...
  âœ“ å¾®å°æŒ‡æ•£æˆ¶å¤šç©ºæ¯”: -22.17%
  âœ“ æ”¶ç›¤åƒ¹: 33,691
  âœ“ æœªå¹³å€‰é‡: 69,324
```

### 5ï¸âƒ£ é©—è­‰æ•¸æ“š (2 åˆ†é˜)
```bash
python verify_scraper.py
```

æ‡‰è©²çœ‹åˆ°ï¼š
```
âœ… æ‰€æœ‰é©—è­‰é€šéï¼çˆ¬èŸ²æ•¸æ“šèˆ‡å®˜æ–¹ä¸€è‡´
```

### 6ï¸âƒ£ æ”¶é›†æ­·å²ï¼ˆå¯é¸ï¼Œ10 åˆ†é˜ï¼‰
```bash
python collect_mxf_history.py
# é¸æ“‡ 1: éå» 30 å¤©
```

### 7ï¸âƒ£ æª¢æŸ¥ JSON è¼¸å‡º (1 åˆ†é˜)
```bash
cat data/futures_data.json | python -m json.tool | head -30
```

---

## âš ï¸ å¸¸è¦‹å•é¡Œé€ŸæŸ¥

### âŒ å•é¡Œ: `ModuleNotFoundError: No module named 'scraper_taifex_v2'`
**è§£æ±º:** æª”æ¡ˆåç¨±éŒ¯èª¤
```bash
cd ~/MyStock/backend
mv scraper_taifex_new.py scraper_taifex_v2.py
```

### âŒ å•é¡Œ: `Table mxf_futures_data doesn't exist`
**è§£æ±º:** å¿˜è¨˜å‡ç´šè³‡æ–™åº«
```bash
python upgrade_database.py
```

### âŒ å•é¡Œ: é©—è­‰å¤±æ•—ï¼Œæ•¸æ“šä¸ä¸€è‡´
**å¯èƒ½åŸå› :**
1. æœŸäº¤æ‰€ç¶²ç«™çµæ§‹æ”¹è®Š â†’ ç­‰æˆ‘æ›´æ–°è§£æé‚è¼¯
2. æŸ¥è©¢çš„æ—¥æœŸæ²’æœ‰äº¤æ˜“ â†’ æ›å€‹æ—¥æœŸè©¦è©¦
3. ç¶²è·¯é€£ç·šå•é¡Œ â†’ æª¢æŸ¥ç¶²è·¯

**é™¤éŒ¯æ­¥é©Ÿ:**
```bash
python -c "from scraper_taifex_v2 import TAIFEXScraper; s=TAIFEXScraper(); s.get_retail_ratio('2026/02/11', 'MXF', debug=True)"
```

### âŒ å•é¡Œ: JSON æª”æ¡ˆæ²’æœ‰ MXF è³‡æ–™
**è§£æ±º:** æ‰‹å‹•åŸ·è¡Œæ”¶é›†å™¨
```bash
python retail_ratio_collector_v2.py
```

---

## ğŸ“Š è³‡æ–™é©—è­‰æ¸…å–®

åŸ·è¡Œå®Œæˆå¾Œï¼Œè«‹é©—è­‰ä»¥ä¸‹é …ç›®ï¼š

- [ ] è³‡æ–™åº«æœ‰ `mxf_futures_data` è¡¨
- [ ] æœ€è¿‘ä¸€å€‹äº¤æ˜“æ—¥æœ‰ MXF æ•¸æ“š
- [ ] `data/futures_data.json` åŒ…å« `mxf` æ¬„ä½
- [ ] æ•£æˆ¶å¤šç©ºæ¯”æ•¸å€¼åˆç†ï¼ˆ-30% ~ +30%ï¼‰
- [ ] æœªå¹³å€‰é‡ > 50,000
- [ ] æ”¶ç›¤åƒ¹åœ¨ 30,000 ~ 40,000 ç¯„åœ

é©—è­‰æŒ‡ä»¤ï¼š
```bash
sqlite3 data/market_data.db "SELECT date, retail_ratio, total_oi FROM mxf_futures_data ORDER BY date DESC LIMIT 5;"
```

---

## ğŸš€ éƒ¨ç½²åˆ°ç”Ÿç”¢

### æ›´æ–°å®šæ™‚ä»»å‹™

å¦‚æœä½¿ç”¨ launchd (macOS):
```bash
# ç·¨è¼¯ plist
nano ~/Library/LaunchAgents/com.mystock.daily.plist

# ç¢ºèªåŸ·è¡Œçš„æ˜¯ run_daily.py (æ–°ç‰ˆ)
# é‡æ–°è¼‰å…¥
launchctl unload ~/Library/LaunchAgents/com.mystock.daily.plist
launchctl load ~/Library/LaunchAgents/com.mystock.daily.plist
```

å¦‚æœä½¿ç”¨ cron (Linux):
```bash
crontab -e
# 30 20 * * * cd /path/to/backend && python run_daily.py >> logs/daily.log 2>&1
```

---

## ğŸ¨ å‰ç«¯æ›´æ–°è¦é»

1. **è®€å–æ–°çš„ JSON æ ¼å¼**
   ```javascript
   const data = await fetch('/data/futures_data.json').then(r => r.json());
   const mxfHistory = data.history.mxf;  // å¾®å°æŒ‡
   const txHistory = data.history.tx;     // å¤§å°
   ```

2. **é¡¯ç¤ºå¾®å°æŒ‡åœ–è¡¨**ï¼ˆé¡ä¼¼ç¬¬äºŒå¼µåœ–ï¼‰
   - X è»¸: æ—¥æœŸ
   - Y è»¸: æ•£æˆ¶å¤šç©ºæ¯” (%)
   - 0 ç·šç‚ºåˆ†ç•Œç·š
   - æ­£å€¼ = ç¶ è‰²æŸ±ï¼ˆåå¤šï¼‰
   - è² å€¼ = ç´…è‰²æŸ±ï¼ˆåç©ºï¼‰

3. **èƒŒé›¢æç¤º**
   ```javascript
   if (mxf.retail_ratio > 15 && tx.retail_ratio < -5) {
     alert('âš ï¸ æ•£æˆ¶è¿½é«˜ï¼Œæ³•äººä¿å®ˆï¼Œæ³¨æ„çŸ­ç·šé¢¨éšª');
   }
   ```

---

## ğŸ“ éœ€è¦å”åŠ©ï¼Ÿ

æ•´åˆéç¨‹ä¸­é‡åˆ°ä»»ä½•å•é¡Œï¼š

1. å…ˆæª¢æŸ¥æœ¬æ¸…å–®çš„ã€Œå¸¸è¦‹å•é¡Œã€
2. åŸ·è¡Œ `verify_scraper.py` ç¢ºèªçˆ¬èŸ²
3. æŸ¥çœ‹ `logs/` ç›®éŒ„çš„éŒ¯èª¤è¨Šæ¯
4. æä¾›å®Œæ•´éŒ¯èª¤è¨Šæ¯è®“æˆ‘å”åŠ©

---

## âœ… å®Œæˆç¢ºèª

å…¨éƒ¨æ•´åˆå®Œæˆå¾Œï¼Œæ‚¨æ‡‰è©²èƒ½ï¼š

- âœ… æ¯æ—¥è‡ªå‹•æ”¶é›† MXF å¾®å°æŒ‡æ•¸æ“š
- âœ… åœ¨ `data/futures_data.json` çœ‹åˆ°æœ€æ–°æ•¸æ“š
- âœ… è³‡æ–™åº«æœ‰éå» 30 å¤©çš„æ­·å²æ•¸æ“š
- âœ… é©—è­‰è…³æœ¬é€šéæ‰€æœ‰æª¢æŸ¥

**æ­å–œï¼æ‚¨ç¾åœ¨æ“æœ‰ TX + MXF é›™æœŸè²¨ç›£æ§ç³»çµ±ï¼** ğŸ‰
